{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cczt-GeZ9z-f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cczt-GeZ9z-f",
    "outputId": "b04631cd-d89d-448b-dc82-74b57ae5238a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'frozen_east_text_detection.pb'...\n",
      "remote: Enumerating objects: 3, done.\u001b[K\n",
      "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 3\u001b[K\n",
      "Unpacking objects: 100% (3/3), 85.66 MiB | 9.51 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/oyyd/frozen_east_text_detection.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "37ddd62f",
   "metadata": {
    "id": "37ddd62f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def decode(scores, geometry):\n",
    "    detections = []\n",
    "    confidences = []\n",
    "    height, width = scores.shape[2:4]\n",
    "    for y in range(0, height):\n",
    "        scores_data = scores[0][0][y]\n",
    "        x0_data = geometry[0][0][y]\n",
    "        x1_data = geometry[0][1][y]\n",
    "        x2_data = geometry[0][2][y]\n",
    "        x3_data = geometry[0][3][y]\n",
    "        angles_data = geometry[0][4][y]\n",
    "        for x in range(0, width):\n",
    "            score = scores_data[x]\n",
    "            if score < 0.5:\n",
    "                continue\n",
    "            offset_x = x * 4.0\n",
    "            offset_y = y * 4.0\n",
    "            angle = angles_data[x]\n",
    "            cos_a = np.cos(angle)\n",
    "            sin_a = np.sin(angle)\n",
    "            h = x0_data[x] + x2_data[x]\n",
    "            w = x1_data[x] + x3_data[x]\n",
    "            end_x = int(offset_x + (cos_a * x1_data[x]) + (sin_a * x2_data[x]))\n",
    "            end_y = int(offset_y - (sin_a * x1_data[x]) + (cos_a * x2_data[x]))\n",
    "            start_x = int(end_x - w)\n",
    "            start_y = int(end_y - h)\n",
    "            detections.append((start_x, start_y, end_x, end_y))\n",
    "            confidences.append(score)\n",
    "    boxes = non_max_suppression(np.array(detections), probs=confidences, overlapThresh=0.5)\n",
    "    return boxes\n",
    "\n",
    "def non_max_suppression(boxes, probs=None, overlapThresh=0.3):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    pick = []\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    if probs is not None:\n",
    "        idxs = np.argsort(probs)\n",
    "    else:\n",
    "        idxs = np.argsort(y2)\n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        suppress = [last]\n",
    "        for pos in range(0, last):\n",
    "            j = idxs[pos]\n",
    "            xx1 = max(x1[i], x1[j])\n",
    "            yy1 = max(y1[i], y1[j])\n",
    "            xx2 = min(x2[i], x2[j])\n",
    "            yy2 = min(y2[i], y2[j])\n",
    "            w = max(0, xx2 - xx1 + 1)\n",
    "            h = max(0, yy2 - yy1 + 1)\n",
    "            overlap = float(w * h) / area[j]\n",
    "            if overlap > overlapThresh:\n",
    "                suppress.append(pos)\n",
    "        idxs = np.delete(idxs, suppress)\n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "\n",
    "\n",
    "def resize_image(image, height=640, width=640):\n",
    "    \"\"\"Resizes an input image to the required size of the EAST text detection model.\"\"\"\n",
    "    # Get the original image dimensions\n",
    "    orig_height, orig_width = image.shape[:2]\n",
    "\n",
    "    # Calculate the ratio of the original dimensions to the desired dimensions\n",
    "    height_ratio = height / float(orig_height)\n",
    "    width_ratio = width / float(orig_width)\n",
    "\n",
    "    # Determine which ratio to use for resizing\n",
    "    ratio = min(height_ratio, width_ratio)\n",
    "\n",
    "    # Calculate the new dimensions\n",
    "    new_height = int(orig_height * ratio)\n",
    "    new_width = int(orig_width * ratio)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_image = cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "    # Pad the image to the required size\n",
    "    delta_w = width - new_width\n",
    "    delta_h = height - new_height\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "\n",
    "    #Return the resized and padded image\n",
    "    return padded_image, top, bottom, left, right\n",
    "\n",
    "\n",
    "def get_text(image_path, net):\n",
    "\n",
    "  # Define the path to the pre-trained EAST model\n",
    "\n",
    "  # Load the input image\n",
    "  image = cv2.imread(image_path)\n",
    "  height = image.shape[0]\n",
    "  width  = image.shape[1]\n",
    "  new_height = 640\n",
    "  new_width = 640\n",
    "  image, top, bottom, left, right = resize_image(image, height=new_height, width=new_width)\n",
    "  w_ratio = width / (new_width - left - right)\n",
    "  h_ratio = height / (new_height - top - bottom)\n",
    "  # Get the height and width of the image\n",
    "  height, width, _ = image.shape\n",
    "\n",
    "  # Load the pre-trained EAST model\n",
    "  # Create a blob from the image and set the input for the EAST model\n",
    "  blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(width, height), mean=(123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "  net.setInput(blob)\n",
    "  # Get the output from the EAST model\n",
    "  scores, geometry = net.forward([\"feature_fusion/Conv_7/Sigmoid\", \"feature_fusion/concat_3\"])\n",
    "  # Decode the output to get the bounding boxes of the detected text\n",
    "  boxes = decode(scores, geometry)\n",
    "  # Draw the bounding boxes on the image\n",
    "\n",
    "  bbox_list  = []\n",
    "  for box in boxes:\n",
    "      x1, y1, x2, y2 = map(int, box)\n",
    "      x1 = (x1 - left) * w_ratio\n",
    "      x2 = (x2 - left) * w_ratio\n",
    "      \n",
    "      y1 = (y1 - top) * h_ratio\n",
    "      y2 = (y2 - top) * h_ratio\n",
    "      bbox_list.append({\"class\":\"text\",\"bbox\":[x1, y1, x2, y2]})\n",
    "      # o_im = cv2.imread(image_path)\n",
    "      # cv2.rectangle(o_im, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "      # cv2.imwrite(\"arsla.png\",o_im)\n",
    "  return bbox_list\n",
    "\n",
    "\n",
    "\n",
    "def get_dict_for_annotations():\n",
    "    return {\n",
    "        \"_via_settings\": {\n",
    "            \"ui\": {\n",
    "                \"annotation_editor_height\": 25,\n",
    "                \"annotation_editor_fontsize\": 0.8,\n",
    "                \"leftsidebar_width\": 18,\n",
    "                \"image_grid\": {\n",
    "                    \"img_height\": 80,\n",
    "                    \"rshape_fill\": \"none\",\n",
    "                    \"rshape_fill_opacity\": 0.3,\n",
    "                    \"rshape_stroke\": \"yellow\",\n",
    "                    \"rshape_stroke_width\": 2,\n",
    "                    \"show_region_shape\": True,\n",
    "                    \"show_image_policy\": \"all\"\n",
    "                },\n",
    "                \"image\": {\n",
    "                    \"region_label\": \"class\",\n",
    "                    \"region_color\": \"__via_default_region_color__\",\n",
    "                    \"region_label_font\": \"10px Sans\",\n",
    "                    \"on_image_annotation_editor_placement\": \"NEAR_REGION\"\n",
    "                }\n",
    "            },\n",
    "            \"core\": {\n",
    "                \"buffer_size\": 18,\n",
    "                \"filepath\": {},\n",
    "                \"default_filepath\": \"\"\n",
    "            },\n",
    "            \"project\": {\n",
    "                \"name\": \"idcard_annotations\"\n",
    "            }\n",
    "        },\n",
    "        \"_via_img_metadata\": {},\n",
    "        \"_via_attributes\": {\n",
    "            \"region\": {\n",
    "                \"class\": {\n",
    "                    \"type\": \"checkbox\",\n",
    "                    \"description\": \"\",\n",
    "                    \"options\": {'\"\"': ''},\n",
    "                    \"default_options\": {}\n",
    "                }\n",
    "            },\n",
    "            \"file\": {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def bboxes_to_via_annotations(bboxes):\n",
    "    via_annotaitons_data = get_dict_for_annotations()\n",
    "    for im_path, bbox in bboxes.items():\n",
    "        im_name = im_path.split(\"/\")[-1]\n",
    "        im_size = os.path.getsize(im_path)\n",
    "        im_key = im_name + str(im_size)\n",
    "        regions = []\n",
    "        for b in bbox:\n",
    "            regions += [\n",
    "                {\n",
    "                    \"shape_attributes\": {\n",
    "                        \"name\": \"rect\",\n",
    "                        \"x\": b[\"bbox\"][0],\n",
    "                        \"y\": b[\"bbox\"][1],\n",
    "                        \"width\": b[\"bbox\"][2] - b[\"bbox\"][0],\n",
    "                        \"height\": b[\"bbox\"][3] - b[\"bbox\"][1]\n",
    "                    },\n",
    "                    \"region_attributes\": {\n",
    "                        \"class\": {\n",
    "                            b[\"class\"]: True\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "            via_annotaitons_data[\"_via_attributes\"][\"region\"][\"class\"][\"options\"][b[\"class\"]] = \"\"\n",
    "        via_annotaitons_data[\"_via_img_metadata\"][im_key] = {\n",
    "            \"filename\": im_name,\n",
    "            \"size\": im_size,\n",
    "            \"regions\": regions,\n",
    "            \"file_attributes\": {}\n",
    "        }\n",
    "    return via_annotaitons_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c8bb5d2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8bb5d2a",
    "outputId": "e21bc7e3-f2a2-423b-fb88-cc4226d1f777"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:17<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "im_dir_path = \"/content/test\"\n",
    "\n",
    "\n",
    "model_path = '/content/frozen_east_text_detection.pb/frozen_east_text_detection.pb'\n",
    "net = cv2.dnn.readNet(model_path)\n",
    "\n",
    "\n",
    "im_list = glob.glob(os.path.join(im_dir_path,\"*.*g\")) + glob.glob(os.path.join(im_dir_path,\"*.*G\"))\n",
    "\n",
    "import tqdm\n",
    "bboxes = {}\n",
    "for im_path in tqdm.tqdm(im_list):\n",
    "    bboxes[im_path] = get_text(im_path, net)\n",
    "\n",
    "\n",
    "via_annotaitons_data = bboxes_to_via_annotations(bboxes)\n",
    "json.dump(via_annotaitons_data, open(\"annotations.json\",\"w\"))\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80_ulfS3-PrN",
   "metadata": {
    "id": "80_ulfS3-PrN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
